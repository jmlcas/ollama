# Ollama

Ver en "http://localhost:3000"

La version actual de chatbot-ollama no descarga el modelo automaticamente.

Librería de modelos: https://ollama.com/library
 
Vas a tener que correr este comando cada vez que necesites un modelo nuevo:
 
docker exec ollama ollama pull gpt-oss:latest #ocupa 14 GB

docker exec ollama ollama pull deepseek-r1:7b #ocupa 4,7 GB

docker exec ollama ollama pull gemma3:1b #ocupa 850 MB


Ver vídeo:

[![Alt text](https://img.youtube.com/vi/DEcP4bkvHG4/0.jpg)](https://www.youtube.com/watch?v=DEcP4bkvHG4)

