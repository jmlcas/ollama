# Ollama

Ver en "http://localhost:3000"

 La version actual de chatbot-ollama no descarga el modelo automaticamente.

 Lirería de modelos: https://ollama.com/library
 
 Vas a tener que correr este comando cada vez que necesites un modelo nuevo:
 
docker exec ollama ollama pull codellama    # codellama = nombre de modelo


 Ver vídeo:

 [![Alt text](https://img.youtube.com/vi/DEcP4bkvHG4/0.jpg)](https://www.youtube.com/watch?v=DEcP4bkvHG4)

